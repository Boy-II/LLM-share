# Prompt Control 雙LLM格式化系統 - 完整指南

## 📚 文檔結構

本項目包含完整的雙LLM工作流程設計,用於將主LLM生成的粗糙標籤格式化為ComfyUI Prompt Control格式。

### 核心文檔

1. **`8b_formatting_rules.md`** (17KB) - 8B模型核心判斷規則
   - AREA/MASK畫面佔比判斷
   - CUT使用時機判斷
   - LoRA和提示詞插入點判斷
   - 包含決策流程圖和實例

2. **`main_llm_guide.md`** (14KB) - 主LLM標籤生成指南
   - 必需元素清單(人物、外觀、服裝、動作、場景)
   - 圖片比例判斷規則(1人→豎版, 2人→橫版, 3+人→寬橫版)
   - 標籤生成模板和檢查清單

3. **`quick_reference.md`** (10KB) - 快速參考卡
   - 完整工作流程圖
   - 三大決策樹(AREA、CUT、LoRA)
   - 速查表和常見場景範例

### 輔助文檔

4. **`format_system_prompt.md`** (3.5KB) - 8B模型系統提示詞
   - 完整的Prompt Control語法規則
   - 轉換範例和處理原則
   - 可直接用於8B模型的system prompt

5. **`test_cases.md`** (4.9KB) - 測試案例集
   - 15+基礎測試案例
   - 評估標準和檢查項
   - 覆蓋各種場景類型

6. **`training_cases.md`** (23KB) - 30個實戰訓練案例
   - 從簡單到複雜的完整案例
   - 包含決策分析過程
   - 期望輸出對照

7. **`integration_guide.md`** (12KB) - 整合實現方案
   - 三種整合方案(STscript/Python/擴展)
   - 模型選擇和配置
   - 性能優化和故障排除

---

## 🎯 快速開始

### 第一步: 理解工作流程

```
用戶輸入
    ↓
主LLM (語義分析)
    ├─ 分析情境和情感
    ├─ 確定人物和關係
    ├─ 描述外觀和動作
    └─ 判斷圖片比例
    ↓
粗糙標籤輸出
    ↓
8B模型 (格式化)
    ├─ AREA座標計算
    ├─ CUT使用判斷
    ├─ LoRA時間調度
    └─ 權重設置
    ↓
Prompt Control格式化標籤
    ↓
ComfyUI生成圖片
```

### 第二步: 選擇8B模型

**推薦: Qwen2.5 14B Instruct Q5量化**

安裝(使用Ollama):
```bash
ollama pull qwen2.5:14b-instruct-q5_K_M
```

備選:
- Llama 3.1 8B Instruct (更快,記憶體更低)
- Mistral Small 22B (更高質量)

### 第三步: 配置系統提示詞

使用 `format_system_prompt.md` 作為8B模型的system prompt。

測試命令:
```bash
ollama run qwen2.5:14b-instruct-q5_K_M
```

然後貼上系統提示詞,再輸入測試案例。

### 第四步: 驗證格式化能力

使用 `test_cases.md` 或 `training_cases.md` 中的案例進行測試。

基礎測試:
```
輸入: 紅髮女孩,藍色眼睛,白色連衣裙,站立,在公園

期望輸出:
<lora:illustrious:0.85> 1girl,
(red hair:1.2), (blue eyes:1.1),
(white dress:1.1), standing
BREAK
in park
[::<lora:eye_detail:0.8>:0.7]
```

### 第五步: 整合到工作流

根據 `integration_guide.md` 選擇適合的整合方案。

---

## 📖 學習路徑

### 新手路徑

1. **閱讀** `quick_reference.md` - 理解整體流程 (20分鐘)
2. **閱讀** `main_llm_guide.md` 第一部分 - 必需元素 (15分鐘)
3. **閱讀** `8b_formatting_rules.md` 規則1 - AREA判斷 (20分鐘)
4. **實踐** `training_cases.md` 案例1-5 (30分鐘)

### 進階路徑

1. **深入** `8b_formatting_rules.md` 完整內容 (1小時)
2. **實踐** `training_cases.md` 案例11-20 (1小時)
3. **研究** Prompt Control官方文檔 (選讀)
4. **調試** 實際案例並優化

### 專家路徑

1. **完成** 所有30個training cases (2-3小時)
2. **優化** system prompt針對你的用例
3. **開發** 自定義整合方案
4. **建立** 自己的案例庫

---

## 🔑 核心概念速查

### 主LLM的5個必需元素

1. **人物** - 數量+性別 (1girl, 2boys)
2. **外觀** - 髮色+髮型+眼色
3. **服裝** - 類型+顏色
4. **動作** - 姿勢+表情+互動
5. **場景** - 位置+環境

### 8B模型的3大判斷

1. **AREA判斷**
   - 1人: 通常不用
   - 2人並排: AREA(0,0,0.5,1) & (0.5,0,0.5,1)
   - 2人擁抱: 不用AREA
   - 3人: 三等分
   - 4人+: 避免使用

2. **CUT判斷**
   - 2+顏色對象 且 空間重疊 → 用CUT
   - 交叉色彩(金髮藍眼 vs 藍髮金眼) → 必用CUT
   - 已用AREA隔離 → 通常不用CUT

3. **LoRA時間判斷**
   - 風格: 0.0-1.0
   - 構圖: 0.0-0.5
   - 角色: 0.0-0.7
   - 眼睛細節: 0.7-1.0
   - 手部: 0.6-1.0

### 圖片比例速記

- **1人**: 3:4 豎版 (例外: 躺臥→橫版)
- **2人**: 4:3 橫版 或 1:1 方形
- **3人+**: 16:9 寬橫版

---

## 💡 實戰技巧

### 技巧1: 權重設置

```
主要特徵 (髮色): 1.2-1.3
次要特徵 (眼色): 1.1-1.2
動作表情: 1.0-1.2
背景元素: 0.8-1.0
```

### 技巧2: BREAK使用

超過75個token或概念切換時使用BREAK:
```
角色描述 BREAK 場景描述 BREAK 細節LoRA
```

### 技巧3: CUT關鍵詞處理

```
# 單詞遮罩
[CUT:white cat:white]

# 詞組遮罩 (用下劃線)
[CUT:blue eyes girl:blue_eyes]
```

### 技巧4: 動態權重

```
# 光線漸強
(lighting:0.5:1.3:0.0,1.0)

# 元素淡出
(element:1.2:0.6:0.0,0.5)
```

---

## 🛠️ 故障排除

### 問題1: 人物特徵混淆

**症狀**: 金髮女孩出現藍眼睛,但應該是綠眼睛
**原因**: 未使用CUT或CUT關鍵詞錯誤
**解決**: 
```
[CUT:golden-haired girl, green eyes:golden green_eyes]
```

### 問題2: 區域分布錯誤

**症狀**: 左右兩人位置顛倒
**原因**: AREA座標錯誤
**解決**: 檢查座標
```
左: (0, 0, 0.5, 1)  # x=0開始
右: (0.5, 0, 0.5, 1)  # x=0.5開始
```

### 問題3: 細節不足

**症狀**: 眼睛不夠精細
**原因**: eye_detail LoRA太早介入
**解決**:
```
[::<lora:eye_detail:0.8>:0.7]  # 0.7開始,不是0.2
```

### 問題4: 構圖崩潰

**症狀**: 姿勢扭曲
**原因**: dynamic_pose LoRA太晚介入
**解決**:
```
[<lora:dynamic_pose:0.9>::0.5]  # 前半段,不是後半段
```

---

## 📊 性能參考 (RTX 5080 + 64GB RAM)

| 模型 | 量化 | VRAM | 速度 | 適用場景 |
|------|------|------|------|----------|
| Qwen2.5 7B | Q5_K_M | ~5GB | 80-100 t/s | 快速原型 |
| Qwen2.5 14B | Q5_K_M | ~9GB | 50-70 t/s | **推薦平衡** |
| Llama 3.1 8B | Q5_K_M | ~6GB | 70-90 t/s | 備選方案 |
| Mistral 22B | Q5_K_M | ~14GB | 30-40 t/s | 高質量 |

格式化任務通常100-300 tokens,耗時1-3秒。

---

## 🎓 進階主題

### 複雜時間調度

```
# 三階段表情變化
[happy:[neutral:sad:0.7]:0.3]

# 序列調度
[SEQ:元素1:0.2:元素2:0.5:元素3:0.8]

# 交替
[晴天|雨天:0.1]  # 每0.1交替
```

### 多LoRA組合策略

```
# 風格(全程) + 動態(前期) + 細節(後期)
<lora:style:0.85>
[<lora:dynamic:0.9>::0.5]
[::<lora:eye_detail:0.8>:0.7]
[::<lora:hand_fix:0.9>:0.6]
```

### Attention Couple (進階)

當AREA不夠用時:
```
COUPLE(
  base_prompt,
  target1 in MASK(...),
  target2 in MASK(...)
)
```

---

## 📝 檢查清單模板

### 主LLM輸出檢查

```
□ [ASPECT_RATIO] X:X [/ASPECT_RATIO] 已標註
□ 人物數量性別明確
□ 髮色髮型描述完整
□ 服裝類型清楚
□ 動作姿勢明確
□ 場景背景設定
□ 多人時各人物區分清楚
□ 無Prompt Control語法
□ 無歧義描述
```

### 8B格式化輸出檢查

```
□ LoRA語法正確 <lora:name:weight>
□ AREA座標正確 (x,y,w,h)
□ CUT使用恰當 [CUT:text:tokens]
□ 權重範圍合理 0.8-1.3
□ 時間點設置正確
□ BREAK分段清晰
□ 無語法錯誤
□ 可在ComfyUI運行
```

---

## 🔗 相關資源

### Prompt Control官方文檔

- `官方文件/README.md` - 總覽
- `官方文件/basic.md` - 基礎語法
- `官方文件/schedules.md` - 調度語法
- `官方文件/attention_couple.md` - 區域控制

### 推薦閱讀順序

1. 本項目 `quick_reference.md`
2. 官方 `README.md`
3. 官方 `basic.md`
4. 本項目 `8b_formatting_rules.md`
5. 官方 `schedules.md`

---

## 🚀 下一步行動

### 立即可做

1. ✅ 安裝Qwen2.5 14B模型
2. ✅ 測試基礎格式化(案例1-5)
3. ✅ 調整system prompt
4. ✅ 驗證ComfyUI可用性

### 短期目標

1. ⬜ 完成30個訓練案例
2. ⬜ 整合到SillyTavern工作流
3. ⬜ 建立自己的測試案例庫
4. ⬜ 優化參數配置

### 長期優化

1. ⬜ Fine-tune 8B模型(可選)
2. ⬜ 自動化測試流程
3. ⬜ 建立案例數據庫
4. ⬜ 社區分享經驗

---

## 💬 常見問題

**Q: 為什麼需要兩個LLM?**
A: 主LLM專注語義理解和創意,8B模型專注格式轉換。分工明確,各司其職,效率更高。

**Q: 8B模型夠用嗎?**
A: 完全夠用!格式化是規則驅動的結構化任務,8B甚至7B都能勝任。

**Q: 能用更大的模型嗎?**
A: 可以,但性價比不高。14B-20B已經是甜蜜點。

**Q: 必須用Ollama嗎?**
A: 不必須。LM Studio、KoboldCpp、vLLM等都可以。

**Q: 能否跳過主LLM直接格式化?**
A: 不建議。主LLM提供必要的語義理解和上下文連接。

**Q: 格式化後還需要人工檢查嗎?**
A: 初期建議檢查,熟練後可以直接使用。建立測試集可以提高信心。

**Q: 支援中文輸入嗎?**
A: 主LLM可以接受中文,但建議輸出英文標籤。8B模型處理英文更可靠。

---

## 📧 反饋和改進

這是一個持續改進的項目。建議:

1. **記錄失敗案例** - 遇到問題時記錄下來
2. **分享成功案例** - 發現好的pattern時記錄
3. **優化system prompt** - 根據實際使用調整
4. **擴充測試集** - 添加你的特殊用例

---

## 🎉 總結

你現在擁有:
- ✅ 完整的雙LLM工作流程設計
- ✅ 詳細的判斷規則和決策樹
- ✅ 30個實戰訓練案例
- ✅ 可直接使用的system prompt
- ✅ 多種整合方案
- ✅ 故障排除指南

**核心原則**: 
- 主LLM = 語義理解
- 8B模型 = 語法轉換
- 各司其職,配合完美!

開始你的Prompt Control格式化之旅吧! 🚀
